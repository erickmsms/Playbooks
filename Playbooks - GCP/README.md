# Playbooks - GCP

Este diretÃ³rio contÃ©m guias prÃ¡ticos, scripts de automaÃ§Ã£o e documentaÃ§Ã£o tÃ©cnica para implementaÃ§Ã£o de pipelines de dados no Google Cloud Platform (GCP), com foco em **ingestÃ£o**, **transformaÃ§Ã£o** e **estimativa de custos**.

---

## ğŸ“ Estrutura da Pasta

```
Playbooks - GCP/
â”œâ”€â”€ README.md                             # Este arquivo
â”œâ”€â”€ GCP - Cloud Run Jobs.pdf               # Guia completo de ingestÃ£o com Cloud Run Jobs
â”œâ”€â”€ GCP - Estimativa Custos.pdf            # Metodologia para estimar custos em projetos GCP
â”œâ”€â”€ Script Deploy Bronze/                   # Pipeline de ingestÃ£o (camada Bronze)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ deploybronze.sh
â””â”€â”€ Script Deploy DBT/                      # Pipeline de transformaÃ§Ã£o com DBT
    â”œâ”€â”€ .dockerignore
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ deploydbt.sh
    â”œâ”€â”€ entrypoint.sh
    â””â”€â”€ profiles.yml
```

---

## ğŸ“˜ DocumentaÃ§Ã£o TÃ©cnica

### 1. `GCP - Cloud Run Jobs.pdf`
Guia passo a passo para implementar **pipelines de ingestÃ£o recorrente** usando:
- Cloud Run Jobs
- Cloud Storage (particionamento por data)
- BigQuery (External Tables)
- Agendamento com Scheduler

Inclui desde a estrutura do projeto atÃ© deploy e carga histÃ³rica.

### 2. `GCP - Estimativa Custos.pdf`
Metodologia padronizada para estimar custos de infraestrutura GCP em projetos de dados. Aborda:
- Dimensionamento de Cloud Storage, BigQuery e Cloud Run
- Tabelas de referÃªncia por tipo de fonte
- CÃ¡lculo de volume mensal e histÃ³rico
- Rateio de custos por fonte

---

## âš™ï¸ Scripts de AutomaÃ§Ã£o

### ğŸ”¹ `Script Deploy Bronze/`
AutomaÃ§Ã£o para deploy de **pipelines de ingestÃ£o (camada Bronze)**.

**Arquivos:**
- `Dockerfile`: Empacota o script de coleta (espera-se um `main.py` no contexto do build)
- `deploybronze.sh`: Script que:
  - Cria/verifica repositÃ³rio no Artifact Registry
  - Builda e faz push da imagem Docker
  - Cria ou atualiza o Cloud Run Job

**Como usar:**
```bash
cd "Script Deploy Bronze"
# Ajuste as variÃ¡veis no script (PROJECT_ID, REGION, etc.)
./deploybronze.sh
```

### ğŸ”¹ `Script Deploy DBT/`
AutomaÃ§Ã£o para deploy de **pipelines de transformaÃ§Ã£o com DBT**.

**Arquivos:**
- `Dockerfile`: Imagem com DBT + entrypoint
- `.dockerignore`: Arquivos ignorados no build
- `entrypoint.sh`: Script de entrada que executa `dbt run`, `test`, `build`, etc.
- `profiles.yml`: ConfiguraÃ§Ã£o de conexÃ£o com BigQuery
- `deploydbt.sh`: Script de deploy similar ao anterior, mas especÃ­fico para DBT

---

## ğŸš€ Como comeÃ§ar

1. **Leia os PDFs** para entender os conceitos e boas prÃ¡ticas
2. **Escolha o tipo de pipeline** que precisa implementar:
   - IngestÃ£o â†’ vÃ¡ para `Script Deploy Bronze/`
   - TransformaÃ§Ã£o com DBT â†’ vÃ¡ para `Script Deploy DBT/`
3. **Adapte os scripts** com seus parÃ¢metros (project-id, regiÃ£o, nome da imagem)
4. **Execute o deploy** e acompanhe os logs no Cloud Run

---

## âœ… PrÃ©-requisitos comuns

- Google Cloud SDK instalado e configurado
- Docker instalado
- PermissÃµes no GCP para:
  - Artifact Registry (criar repositÃ³rios, push de imagens)
  - Cloud Run (criar/atualizar jobs)
  - BigQuery e Cloud Storage (quando aplicÃ¡vel)

---

## ğŸ“Œ ObservaÃ§Ãµes

- Os scripts sÃ£o **idempotentes**: podem ser executados mÃºltiplas vezes
- Sempre revise as variÃ¡veis antes de executar
- Para ambientes reais, considere usar **variÃ¡veis de ambiente ou secrets** no lugar de valores fixos nos scripts

```